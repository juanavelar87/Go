# Go Game con Q-Learning AI ‚ö´Ô∏è‚ö™Ô∏è

## Autores
## Institucion: Universidad Iberoamericana Le√≥n

- **Juan Avelar**
- **Diego Mares**


Este proyecto implementa el juego de mesa **Go** en Python, acompa√±ado de una Inteligencia Artificial basada en **Reinforcement Learning (Q-Learning)**. Incluye una interfaz gr√°fica interactiva y herramientas de visualizaci√≥n para entender el proceso de aprendizaje de la IA. Esto se hace con el prop√≥sito de poner en pr√°ctica los temas vistos en clase a lo largo de la mtaeria y como estos se pueden aplicr. 

## üìã Caracter√≠sticas

### Motor de Juego
- Implementaci√≥n completa de las reglas de Go (captura de piedras, libertades, grupos).
- Soporte para tableros de tama√±o variable (por defecto 3x3 para demostraci√≥n de aprendizaje r√°pido, configurable a 9x9 o 19x19).
- Nota: Ya una vez revisado la parte del proyecto con las pruebas, se compreuba que funciona de mejor manera principalemnte en elementos de tablero 3x3.

### Inteligencia Artificial (Q-Learning)
- **Algoritmo**: Q-Learning tabular con estrategia Epsilon-Greedy.
- **Entrenamiento Asim√©trico**: La IA se entrena especializ√°ndose como el primer jugador (Negras) contra un entorno estoc√°stico (oponente aleatorio).
- **Sistema de Recompensas**:
  - Captura de piedras enemigas (Recompensa alta).
  - P√©rdida de piedras propias (Penalizaci√≥n alta).
  - Control de territorio (Recompensa moderada).
- **Visualizaci√≥n**: Muestra en tiempo real los valores Q (expectativa de recompensa) de cada casilla en la terminal.

### Detalles del algoritmo Q-Learning

- Pol√≠tica: Œµ-greedy
- Par√°metros:
  - Œ± = 0.1
  - Œ≥ = 0.9
  - Œµ = 0.3


### Interfaz
- **GUI (Pygame)**: Interfaz gr√°fica limpia y responsiva para jugar.
- **Terminal**: Visualizaci√≥n ASCII del tablero con "mapa de calor" num√©rico de la toma de decisiones de la IA.

## üõ†Ô∏è Requisitos

El proyecto requiere Python 3 y las siguientes librer√≠as para que se pueda utilizar de forma √≥ptima:

```bash
pip install pygame tqdm
```

## üöÄ C√≥mo Ejecutar

1. Aseg√∫rate de estar en la carpeta del proyecto.
2. Ejecuta el script principal:

```bash
python runner.py
```

3. Sigue las instrucciones en la terminal:
   - **Opci√≥n 1**: Jugar contra la IA.
     - Se entrenar√° un nuevo modelo (o cargar√° uno existente).
     - Elige jugar como **Blanco** (Opci√≥n 2) para enfrentarte a la IA entrenada (que juega con Negras).
   - **Opci√≥n 2**: Modo Humano vs Humano (para probar reglas).

## üéÆ Controles

- **Click Izquierdo**: Colocar una piedra en la intersecci√≥n.
- **Tecla 'E'**: Terminar el juego (pasar/finalizar).
- **Tecla 'R'**: Reiniciar la partida (solo disponible al finalizar el juego).
- **Tecla 'ESC'**: Salir del juego.

## üß† Estructura del C√≥digo

- **`Go.py`**: El coraz√≥n del juego. Contiene las clases `GoBoard` y `GoObject` que manejan la l√≥gica del tablero, grupos de piedras, libertades y la interfaz gr√°fica con Pygame.
- **`AI.py`**: Implementaci√≥n del agente de aprendizaje. Contiene la clase `GoAI`, la tabla Q, y la l√≥gica de entrenamiento (`train_ai`).
- **`runner.py`**: Script orquestador que maneja el men√∫ inicial y el bucle principal del programa.
- **`.pkl`**: Archivos que guardan los valores Q para no reentrenarlo todo el tiempo.

## üîç Detalles T√©cnicos de la IA

La IA aprende a trav√©s de la experiencia simulada.
1. **Estado**: Representado por la configuraci√≥n actual del tablero y el jugador actual.
2. **Acci√≥n**: Coordenadas (x, y) donde colocar una piedra.
3. **Q-Value**: Un n√∫mero que representa "qu√© tan buena es esta jugada a largo plazo".

Durante el entrenamiento, la IA explora millones de posibilidades y actualiza su tabla Q usando la ecuaci√≥n de Bellman:
$$Q(s,a) \leftarrow Q(s,a) + \alpha [R + \gamma \max Q(s',a') - Q(s,a)]$$

## Experimentos y resultados
Entrenamos por 1,000,000 episodios en tableros 3√ó3 y 4√ó4:

- En 3√ó3 el agente domina r√°pidamente.
- En 4√ó4 el espacio de estados explota y muchos Q quedan sin exploraci√≥n.


---
*Desarrollado para el curso de Matem√°ticas para IA.*
